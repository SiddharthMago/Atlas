{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az5UbQ7QI3iM",
        "outputId": "8b42ee03-4a3f-4e7a-e847-c4cc88d1c228"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnH4Lt0kI6bz",
        "outputId": "7379a12c-f938-4324-d4e6-8b40734fcb90"
      },
      "outputs": [],
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install pyg-lib -f https://data.pyg.org/whl/nightly/torch-${TORCH}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znY7yC7UKlE6"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "\n",
        "def create_atlas_graph(data):\n",
        "    \"\"\"\n",
        "    Creates a directed graph for the input.\n",
        "\n",
        "    Parameters:\n",
        "        data (list): A list of place names (countries/cities).\n",
        "\n",
        "    Returns:\n",
        "        G (networkx.DiGraph): A directed graph.\n",
        "    \"\"\"\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    for place in data:\n",
        "        G.add_node(place)\n",
        "        last_letter = place[-1].lower()  # last letter of the name, case-insensitive comparison\n",
        "        for candidate in data:\n",
        "            if candidate[0].lower() == last_letter:\n",
        "                G.add_edge(place, candidate)\n",
        "\n",
        "    return G\n",
        "\n",
        "# Read the list of countries from file.\n",
        "with open(\"/Users/Mago/Desktop/Projects/Atlas/data/countries.txt\", \"r\") as file:\n",
        "    countries = [line.strip() for line in file if line.strip()]\n",
        "\n",
        "country_graph = create_atlas_graph(countries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-xTa4EmJtfm",
        "outputId": "37bda974-adb3-4d05-e61a-6c0d7c0ba67f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import Node2Vec, GCNConv, GAE\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# 1. Convert the NetworkX Graph to a PyG Data Object with Node Features\n",
        "# Build a mapping from country name to numeric index.\n",
        "mapping = {country: i for i, country in enumerate(countries)}\n",
        "\n",
        "# Create node features.\n",
        "# Here we use a simple 2D feature: [normalized(first_letter), normalized(last_letter)]\n",
        "def get_feature(country):\n",
        "    country = country.lower()\n",
        "    first = (ord(country[0]) - ord('a')) / 25.0  # Normalize a=0,...,z=1\n",
        "    last  = (ord(country[-1]) - ord('a')) / 25.0\n",
        "    return [first, last]\n",
        "\n",
        "# Build feature matrix (num_nodes x 2)\n",
        "num_nodes = len(countries)\n",
        "x = torch.tensor([get_feature(country) for country in countries], dtype=torch.float)\n",
        "\n",
        "# Create the edge list (in numeric indices) from the NetworkX graph.\n",
        "edge_list = []\n",
        "for source, target in country_graph.edges():\n",
        "    # Use the mapping to get numeric indices.\n",
        "    i = mapping[source]\n",
        "    j = mapping[target]\n",
        "    edge_list.append([i, j])\n",
        "edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
        "\n",
        "print(\"PyG Data object will have {} nodes and {} edges.\".format(num_nodes, edge_index.size(1)))\n",
        "\n",
        "# Create PyG Data object.\n",
        "data = Data(x=x, edge_index=edge_index)\n",
        "\n",
        "# 3. Unsupervised Link Prediction with Node2Vec (PyG Implementation)\n",
        "# Define Node2Vec parameters.\n",
        "embedding_dim = 13\n",
        "walk_length = 10\n",
        "context_size = 5\n",
        "walks_per_node = 10\n",
        "num_negative_samples = 1\n",
        "\n",
        "nv_epochs = 1000\n",
        "learning_rate_nv = 0.008\n",
        "batch_size_nv = 128\n",
        "\n",
        "# Create Node2Vec model (using the graph’s edge_index).\n",
        "node2vec = Node2Vec(\n",
        "    data.edge_index,\n",
        "    embedding_dim=embedding_dim,\n",
        "    walk_length=walk_length,\n",
        "    context_size=context_size,\n",
        "    walks_per_node=walks_per_node,\n",
        "    num_negative_samples=num_negative_samples,\n",
        "    p=1, q=1,\n",
        "    sparse=True\n",
        ")\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "node2vec = node2vec.to(device)\n",
        "optimizer_n2v = torch.optim.SparseAdam(list(node2vec.parameters()), lr=learning_rate_nv)\n",
        "\n",
        "def train_node2vec():\n",
        "    node2vec.train()\n",
        "    total_loss = 0\n",
        "    loader = node2vec.loader(batch_size=batch_size_nv, shuffle=True, num_workers=0)\n",
        "    num_epochs = nv_epochs\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        epoch_loss = 0\n",
        "        for pos_rw, neg_rw in loader:\n",
        "            pos_rw = pos_rw.to(device)\n",
        "            neg_rw = neg_rw.to(device)\n",
        "            optimizer_n2v.zero_grad()\n",
        "            loss = node2vec.loss(pos_rw, neg_rw)\n",
        "            loss.backward()\n",
        "            optimizer_n2v.step()\n",
        "            epoch_loss += loss.item()\n",
        "        avg_loss = epoch_loss / len(loader)\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Node2Vec Epoch {epoch}, Loss: {avg_loss:.4f}\")\n",
        "        total_loss += avg_loss\n",
        "    return total_loss / num_epochs\n",
        "\n",
        "loss_n2v = train_node2vec()\n",
        "print(\"Final Node2Vec training loss:\", loss_n2v)\n",
        "\n",
        "# Extract the embeddings.\n",
        "embeddings = node2vec.embedding.weight.detach().cpu()\n",
        "\n",
        "# Define a link prediction evaluation function.\n",
        "def evaluate_link_prediction(embeds, pos_edges, num_negatives=None):\n",
        "    num_pos = pos_edges.size(1)\n",
        "    if num_negatives is None:\n",
        "        num_negatives = num_pos\n",
        "    neg_edges = []\n",
        "    while len(neg_edges) < num_negatives:\n",
        "        i = random.randint(0, num_nodes - 1)\n",
        "        j = random.randint(0, num_nodes - 1)\n",
        "        if [i, j] not in edge_list:\n",
        "            neg_edges.append([i, j])\n",
        "    neg_edges = torch.tensor(neg_edges, dtype=torch.long).t().contiguous()\n",
        "\n",
        "    pos_scores = (embeds[pos_edges[0]] * embeds[pos_edges[1]]).sum(dim=1).numpy()\n",
        "    neg_scores = (embeds[neg_edges[0]] * embeds[neg_edges[1]]).sum(dim=1).numpy()\n",
        "\n",
        "    scores = np.concatenate([pos_scores, neg_scores])\n",
        "    labels = np.concatenate([np.ones_like(pos_scores), np.zeros_like(neg_scores)])\n",
        "    auc = roc_auc_score(labels, scores)\n",
        "    return auc\n",
        "\n",
        "# Evaluate on all observed edges.\n",
        "pos_edges = data.edge_index\n",
        "auc_n2v = evaluate_link_prediction(embeddings, pos_edges)\n",
        "print(\"Node2Vec link prediction AUC:\", auc_n2v)\n",
        "\n",
        "# 4. Unsupervised Link Prediction with a GNN (Graph Autoencoder using GCN)\n",
        "# Define a simple two-layer GCN encoder.\n",
        "class GCNEncoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCNEncoder, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
        "        self.conv2 = GCNConv(2 * out_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "hidden_dim = 17\n",
        "learning_rate_gnn = 0.005\n",
        "split_ratio = 0.2\n",
        "gae_epochs = 1000\n",
        "\n",
        "encoder = GCNEncoder(in_channels=data.num_node_features, out_channels=hidden_dim)\n",
        "model = GAE(encoder).to(device)\n",
        "data = data.to(device)\n",
        "optimizer_gae = torch.optim.Adam(model.parameters(), lr=learning_rate_gnn)\n",
        "\n",
        "# Function to mask (remove) a portion of edges for testing.\n",
        "def mask_edges(data, test_ratio=split_ratio):\n",
        "    # Convert edge_index to list format.\n",
        "    edges = data.edge_index.cpu().numpy().T.tolist()\n",
        "    num_edges = len(edges)\n",
        "    num_test = int(test_ratio * num_edges)\n",
        "    random.shuffle(edges)\n",
        "    test_edges = edges[:num_test]\n",
        "    train_edges = edges[num_test:]\n",
        "    train_edge_index = torch.tensor(train_edges, dtype=torch.long).t().contiguous().to(device)\n",
        "    test_edge_index = torch.tensor(test_edges, dtype=torch.long).t().contiguous().to(device)\n",
        "    return train_edge_index, test_edge_index\n",
        "\n",
        "train_edge_index, test_edge_index = mask_edges(data, test_ratio=0.2)\n",
        "print(\"GAE: Training edges:\", train_edge_index.size(1), \"Test edges:\", test_edge_index.size(1))\n",
        "data.train_edge_index = train_edge_index\n",
        "\n",
        "# Train the GAE (unsupervised reconstruction of the graph)\n",
        "def train_gae():\n",
        "    model.train()\n",
        "    optimizer_gae.zero_grad()\n",
        "    z = model.encode(data.x, data.train_edge_index)\n",
        "    loss = model.recon_loss(z, data.train_edge_index)\n",
        "    loss.backward()\n",
        "    optimizer_gae.step()\n",
        "    return loss.item()\n",
        "\n",
        "num_gae_epochs = gae_epochs\n",
        "for epoch in range(1, num_gae_epochs + 1):\n",
        "    loss = train_gae()\n",
        "    if epoch % 20 == 0:\n",
        "        print(f\"GAE Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "\n",
        "# Evaluate GAE link prediction performance.\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    z = model.encode(data.x, data.train_edge_index)\n",
        "\n",
        "def evaluate_gae(z, pos_edge_index, num_negatives=None):\n",
        "    num_pos = pos_edge_index.size(1)\n",
        "    if num_negatives is None:\n",
        "        num_negatives = num_pos\n",
        "    neg_edges = []\n",
        "    while len(neg_edges) < num_negatives:\n",
        "        i = random.randint(0, num_nodes - 1)\n",
        "        j = random.randint(0, num_nodes - 1)\n",
        "        if [i, j] not in edge_list:\n",
        "            neg_edges.append([i, j])\n",
        "    neg_edge_index = torch.tensor(neg_edges, dtype=torch.long).t().contiguous().to(device)\n",
        "\n",
        "    pos_scores = (z[pos_edge_index[0]] * z[pos_edge_index[1]]).sum(dim=1).cpu().numpy()\n",
        "    neg_scores = (z[neg_edge_index[0]] * z[neg_edge_index[1]]).sum(dim=1).cpu().numpy()\n",
        "\n",
        "    scores = np.concatenate([pos_scores, neg_scores])\n",
        "    labels = np.concatenate([np.ones_like(pos_scores), np.zeros_like(neg_scores)])\n",
        "    auc = roc_auc_score(labels, scores)\n",
        "    return auc\n",
        "\n",
        "auc_gae = evaluate_gae(z, test_edge_index)\n",
        "print(\"GAE link prediction AUC:\", auc_gae)\n",
        "\n",
        "print()\n",
        "print(\"-----------------------------------------------------\")\n",
        "print(\"Node2Vec link prediction AUC:\", auc_n2v)\n",
        "print(\"embedding_dim: \", embedding_dim)\n",
        "print(\"walk_length: \", walk_length)\n",
        "print(\"context_size: \", context_size)\n",
        "print(\"walks_per_node: \", walks_per_node)\n",
        "print(\"num_negative_samples: \", num_negative_samples)\n",
        "print(\"nv_epochs: \", nv_epochs)\n",
        "print(\"learning_rate: \", learning_rate_nv)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"-----------------------------------------------------\")\n",
        "print(\"GAE link prediction AUC:\", auc_gae)\n",
        "print(\"hidden_dim: \", hidden_dim)\n",
        "print(\"split_ratio: \", split_ratio)\n",
        "print(\"gae_epochs: \", gae_epochs)\n",
        "print(\"learning_rate: \", learning_rate_gnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46Dlg9xysLSv"
      },
      "source": [
        "# Analysis & Intuition\n",
        "1. Node Features\n",
        "\n",
        "    I built a graph where each country is a node, and there's an edge from one country to another if the last letter of the first country's name matches the first letter of the second. To help represent each country, I created a very simple feature for each node: a two-number vector. The first number represents the normalized value of the country's first letter, and the second represents the normalized value of its last letter. This choice makes sense because our rule for connecting countries is based solely on these letters.\n",
        "\n",
        "2. Node2Vec Approach\n",
        "\n",
        "    For the Node2Vec model, I use a method that is a bit like teaching the computer to explore the graph. Here's how it works:\n",
        "\n",
        "    - Random Walks: The model takes random walks through the graph. This gives the model lots of examples of which countries tend to be connected or appear near each other.\n",
        "\n",
        "    - Learning by Context: While taking these walks, the model learns to predict which countries (nodes) appear together. This is called the skip-gram objective.\n",
        "\n",
        "    - Negative Sampling: To help the model understand what “unrelated” looks like, for every pair of countries that do appear together (a positive example), the model is also shown a negative example—a pair that rarely or never appears together. In my setup, for every positive pair, one negative pair is sampled.\n",
        "\n",
        "    - Link Prediction: After training, each country has a vector (its embedding). The model then uses the dot product (a measure of similarity) between two country embeddings to decide if an edge should exist. If two countries have similar embeddings, they're more likely to be connected.\n",
        "\n",
        "3. GNN (Graph Autoencoder) Approach\n",
        "\n",
        "    For the GNN approach, I use a Graph Autoencoder (GAE) built with a simple two-layer Graph Convolutional Network (GCN):\n",
        "\n",
        "    - Graph Convolution:\n",
        "    The GCN learns new representations (or embeddings) for each country by “mixing” information from its neighbors. This way, each country's new features reflect both its own simple features (first and last letters) and the structure of the graph.\n",
        "\n",
        "    - Masking Edges:\n",
        "    Before training, I remove (mask) a portion of the edges from the graph. The idea is to force the model to learn enough about the overall graph structure so it can predict these missing connections.\n",
        "\n",
        "    - Unsupervised Reconstruction: The GAE is trained to reconstruct (or predict) the presence of the edges that were masked out. This means the model adjusts its internal representations so that, when it tries to recreate the graph, it comes as close as possible to the original structure.\n",
        "\n",
        "    - Link Prediction: Once the model is trained, I evaluate it by comparing the model’s predicted scores (from the dot product of the embeddings) against the actual edges (the ones that were masked for testing). This tells me how well the model learned the underlying connectivity.\n",
        "\n",
        "4. Unsupervised Learning\n",
        "\n",
        "    Both approaches are unsupervised:\n",
        "    - Node2Vec doesn't need any labels because it learns from the way nodes appear together in random walks.\n",
        "\n",
        "    - GAE doesn't need labeled data either because it learns by trying to reconstruct the graph from which some edges have been removed.\n",
        "\n",
        "    In both cases, the training objectives are all about capturing the structure of the graph—learning what makes two nodes likely to be connected—without needing a separate “correct answer” for each edge."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "atlas_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
